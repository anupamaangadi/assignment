pg2
pg2=GET(handle=google,path="nature")
pg2
q()
require("data.table")
require("reshape2")
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
subjtst <- read.table("./GettingData/test/subject_test.txt")
dataset<-cbind(Xsub,y$aname,subject$subject)
Xsub<-X[,grep("-(mean|std)\\(\\)",features$fname)]
trainData <- read.table("./data/train/X_train.txt")
?read.table
trainData <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/train/X_train.txt")
dim(trainData)
head(trainData)
trainLabel <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/train/y_train.txt")
table(trainLabel)
trainSubject <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/train/subject_train.txt")
testData <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/test/X_test.txt")
dim(testData)
testLabel <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/test/y_test.txt")
table(testLabel)
testSubject <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/test/subject_test.txt")
joinData <- rbind(trainData, testData)
dim(joinData)
joinLabel <- rbind(trainLabel, testLabel)
dim(joinLabel)
joinSubject <- rbind(trainSubject, testSubject)
dim(joinSubject)
features <- read.table("C:/Users/Anupama/myown/UCI HAR Datase/data/features.txt")
features <- read.table("C:/Users/Anupama/myown/UCI HAR Datase/features.txt")
features <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/features.txt")
dim(features)
meanStdIndices <- grep("mean\\(\\)|std\\(\\)", features[, 2])
length(meanStdIndices)
joinData <- joinData[, meanStdIndices]
dim(joinData)
names(joinData) <- gsub("\\(\\)", "", features[meanStdIndices, 2])
names(joinData) <- gsub("mean", "Mean", names(joinData))
names(joinData) <- gsub("std", "Std", names(joinData))
names(joinData) <- gsub("-", "", names(joinData))
activity <- read.table("C:/Users/Anupama/myown/UCI HAR Dataset/activity_labels.txt")
activity[, 2] <- tolower(gsub("_", "", activity[, 2]))
substr(activity[2, 2], 8, 8) <- toupper(substr(activity[2, 2], 8, 8))
substr(activity[3, 2], 8, 8) <- toupper(substr(activity[3, 2], 8, 8))
activityLabel <- activity[joinLabel[, 1], 2]
joinLabel[, 1] <- activityLabel
names(joinLabel) <- "activity"
names(joinSubject) <- "subject"
cleanedData <- cbind(joinSubject, joinLabel, joinData)
dim(cleanedData)
write.table(cleanedData, "merged_data.txt")
subjectLen <- length(table(joinSubject))
activityLen <- dim(activity)[1]
columnLen <- dim(cleanedData)[2]
cresult <- matrix(NA, nrow=subjectLen*activityLen, ncol=columnLen)
result <- as.data.frame(cresult)
colnames(result) <- colnames(cleanedData)
row <- 1
for(i in 1:subjectLen) {
for(j in 1:activityLen) {
result[row, 1] <- sort(unique(joinSubject)[, 1])[i]
result[row, 2] <- activity[j, 2]
bool1 <- i == cleanedData$subject
bool2 <- activity[j, 2] == cleanedData$activity
result[row, 3:columnLen] <- colMeans(cleanedData[bool1&bool2, 3:columnLen])
row <- row + 1
}
}
head(result)
write.table(result, "data_with_means.txt")
readData <- function(fname_suffix, path_prefix) {
fpath <- file.path(path_prefix, paste0("y_", fname_suffix, ".txt"))
y_data <- read.table(fpath, header=F, col.names=c("ActivityID"))
fpath <- file.path(path_prefix, paste0("subject_", fname_suffix, ".txt"))
subject_data <- read.table(fpath, header=F, col.names=c("SubjectID"))
data_cols <- read.table("features.txt", header=F, as.is=T, col.names=c("MeasureID", "MeasureName"))
fpath <- file.path(path_prefix, paste0("X_", fname_suffix, ".txt"))
data <- read.table(fpath, header=F, col.names=data_cols$MeasureName)
subset_data_cols <- grep(".*mean\\(\\)|.*std\\(\\)", data_cols$MeasureName)
data <- data[,subset_data_cols]
data$ActivityID <- y_data$ActivityID
data$SubjectID <- subject_data$SubjectID
data
}
readTestData <- function() {
readData("test", "test")
}
readTrainData <- function() {
readData("train", "train")
}
mergeData <- function() {
data <- rbind(readTestData(), readTrainData())
cnames <- colnames(data)
cnames <- gsub("\\.+mean\\.+", cnames, replacement="Mean")
cnames <- gsub("\\.+std\\.+",  cnames, replacement="Std")
colnames(data) <- cnames
data
}
applyActivityLabel <- function(data) {
activity_labels <- read.table("activity_labels.txt", header=F, as.is=T, col.names=c("ActivityID", "ActivityName"))
activity_labels$ActivityName <- as.factor(activity_labels$ActivityName)
data_labeled <- merge(data, activity_labels)
data_labeled
}
getMergedLabeledData <- function() {
applyActivityLabel(mergeData())
}
getTidyData <- function(merged_labeled_data) {
library(reshape2)
id_vars = c("ActivityID", "ActivityName", "SubjectID")
measure_vars = setdiff(colnames(merged_labeled_data), id_vars)
melted_data <- melt(merged_labeled_data, id=id_vars, measure.vars=measure_vars)
# recast
dcast(melted_data, ActivityName + SubjectID ~ variable, mean)
}
createTidyDataFile <- function(fname) {
tidy_data <- getTidyData(getMergedLabeledData())
write.table(tidy_data, fname)
}
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
head(spam)
plot(density(spam$type=="nonspam"))
plot(density(spam$type=="nonspam"])
plot(density(spam$type=="nonspam"]),col="blue",main="",xlab="frequency") lines(density(spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),col="blue",main="",xlab="frequency") lines(density(spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),col="blue",main="",xlab="frequency") lines(density[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),col="blue",main="",xlab="frequency") lines(density(spam$your[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),col="blue",main="",xlab="frequency") lines(density(spam$your[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),col="blue",main="",xlab="frequency")
lines(density(spam$your[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),col="blue",main=" ",xlab="frequency") lines(density(spam$your[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency")
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency of your")
?plot
plot(density(spam$your[spam$type=="nonspam"]),
plot(density(spam$your[spam$type=="nonspam"]),col="blue",main=" ",xlab="frequency") lines(density(spam$your[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency") lines(density(spam$your[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency")
lines(density(spam$your[spam$type="spam"]),col="red")
prediction<-ifelse(spam$your>0.5,"spam","nonspam")
table(prediction,spam$type)/length(spam$type)
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency")
library(kernlab);
data(spam);
set.seed(333)
smallSpam<-spam[sample(dim(spam)[1],size=10),]
spamLabel<-(smallSpam$type="spam")*1+1
spamLabel<-(smallSpam$type="spam")*1 + 1
spamLabel<-(smallSpam$type="spam") * 1 + 1
rule1<-function(x)
{}
rule1<-function(x)
{prediction<-rep(NA,length(x))}
rule1<-function(x)
{
prediction<-rep(NA,length(x))
prediction[x>2.7]<-"spam"
prediction[x<2.40]<-"nonspam"
prediction[(x>=2.40 & x<=2.45)]<-"spam"
prediction[(x>=2.40 & x<=2.70)]<-"nonspam"
returen(prediction)
}
table(rule1(smallSpam$capitalAve),smallSpam$type)
rule1<-function(x)
{
prediction<-rep(NA,length(x))
prediction[x>2.7]<-"spam"
prediction[(x>=2.40 & x<=2.70)]<-"nonspam"
prediction[(x>=2.40 & x<=2.45)]<-"spam"
prediction[x<2.40]<-"nonspam"
return(prediction)
}
table(rule1(smallSpam$capitalAve),smallSpam$type)
rule2<-function(x)
{}
rule2<-function(x)
{}
rule2<-function(x)
{
prediction<-rep(NA,length(x))
prediction[x>2.8]<-"spam"
prediction[x<=2.8]<-"nonspam"
return(prediction)
}
table(rule2(smallSpam$capitalAve),smallSpam$type)
table(rule2(smallSpam$capitalAve),Spam$type)
table(rule1(Spam$capitalAve),Spam$type)
table(rule1(spam$capitalAve),spam$type)
table(rule2(spam$capitalAve),spam$type)
mean(rule1(spam$capitalAve)==spam$type)
spam
col(spam)
summary(spam)
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency")
lines(density(spam$your[spam$type="spam"]),col="red")
plot(density(spam$your[spam$type=="nonspam"]),
+ col="blue",main=" ",xlab="frequency")
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency")
plot(density(spam$your[spam$type=="nonspam"]),
col="blue",main=" ",xlab="frequency")
q()
install.packages("caret")
install.packages("caret")
install.packages("caret")
q()
library(caret);
install.packages("caret")
library(caret);
library(caret)
install.packages("caret")
library(caret)
library(caret)
library(caret)
install.packages("caret")
library(caret)
R_HOME
R.home()
library(swirl)
.libPaths()
library(caret)
install.packages("caret")
install.packages("caret", dependencies = TRUE)
library(caret)
require(caret)
library(tcltk)
library(caret)
install.packages("caret", dependencies = TRUE)
install.packages("klaR")
install.packages("caret")
.libPaths()
library(caret)
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("caret")
install.packages("caret")
library(caret)
library(lattice)
library(ggplot2)
library(lme4)
require(caret)
library(caret)
install.packages("lme4")
library(caret)
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
dim(testing)
set.seed(32343)
modelFit<-train(type ~.,data=training,method="glm")
modelFit
modelFit$finalModel
predictions<-predict(modelFit,newdata=testing)
predictions
confusionMatrix(predictions,testing$type)
intrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
set.seed(32323)
folds<-createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE)
sapply(folds,length)
folds[[1]][1:10]
folds<-createFolds(y=spam$type,k=10,list=TRUE,returnTrain=FALSE)
sapply(folds,length)
folds[[1]][1:10]
folds<-createResample(y=spam$type,times=10,list=TRUE)
sapply(folds,length)
folds[[1]][1:10]
folds<-createTimeSlices(y=time,initialWindow=20,horizon=10)
folds<-createTimeSlices(y=tme,initialWindow=20,horizon=10)
tme<-1:1000
folds<-createTimeSlices(y=tme,initialWindow=20,horizon=10)
names(folds)
folds$train[[1]]
folds$test[[1]]
q()
library(caret)
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
modelFit<-train(type ~.,data=training,method="glm")
set.seed(1235)
library(ISLR)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(caret)
data(wage)
data(Wage)
summary(Wage)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training)
dim(training);dim(testing)
featurePlot(x=training[,c("age","education","jobclass")], y=training$Wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")], y=training$Wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")], y=training$Wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],
, y=training$Wage,
plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qq<-qlot(age,wage,colour=education,data=training)
qq<-qplot(age,wage,colour=education,data=training)
qq+geom_smooth(method='lm',formula=y~x)
library(Hmisc)
install.packageS("Hmisc")
install.packageS("Hmisc")
install.packages("Hmisc")
cutWage<-cut2(training$Wage,g=3)
library(Hmisc)
cutWage<-cut2(training$Wage,g=3)
require(Hmisc)
library(Hmisc)
cutWage<-cut2(training$Wage,g=3)
library(Hmisc)
require(Hmisc)
install.packages("Formula")
install.packages("Formula")
install.packages("Formula")
p1<-qplot(cutWage,age,data=training,fill=cutWage,)
p1<-qplot(cutWage,age,data=training,fill=cutWage,)
p1<-qplot(cutWage,age,data=training,fill=cutWage,
geom=c("boxplot","jitter"))
t1<-table(cutWage,training$jobclass)
t1<-table(cutWage,training$jobclass)
install.packages("Formula")
q()
library(Hmisc)
install.packages("Formula")
library("caret")
library(ISLR)
library(ggplot2)
data(Wage)
cutWage<-cut2(training$Wage,g=3)
install.packages(Hmisc)
library(Hmisc)
install.packages("Hmisc")
install.packages("Hmisc")
library(ISLR)
library(ggplot2)
data(Wage)
cutWage<-cut2(training$wage,g=3)
library(Hmisc)
install.packages("Hmisc")
install.packages("latticeExtra")
install.packages("splines")
install.packages("splines")
install.packages("splines")
library(caret)
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
M<-abs(cor(training[,-58]))
diag(M)<-0
which(M>0.8,arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
plot(spam[,40],spam[,32])
x<-0.71*training$num415+0.71*training$num857
x<-0.71*training$num415-0.71*training$num857
y<-0.71*training$num415-0.71*training$num857
x<-0.71*training$num415+0.71*training$num857
plot(x,y)
smallSpam<-spam[,c(34,32)]
prComp<-prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
preProc<-preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC<-predict(preProc,log10(training[,-58]+1))
modelFit<-train(training ~.,method="glm",data=trainPC)
modelFit<-train(training ~ .,method="glm",data=trainPC)
modelFit<-train(training$type ~ .,method="glm",data=trainPC)
testPC<-predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
librar(caret)
librar(caret);
library(caret);
data(faithful)
set.seed(333)
inTrain<-createDataPartition(y=faithful$waiting,p=0.5,list=FALSE)
trainFaith<-faithful[inTrain,]
testFaith<-faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="waitin",ylab="Duaration")
lm1<-lm(eruptions ~ waiting,data=trainFaith)
summary(lm1)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="waitin",ylab="Duaration")
coef(lm1)[1]+coef(lm1)[2]*80
newdata<-data.frame(waiting=80)
predict(lm1,newdata)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$)^2))
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training)
dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
modFit<-train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel,uniform=TRUE,main="classification tree")
qplot(modFit$finalModel,uniform=TRUE,main="classification tree")
plot(modFit$finalModel,uniform=TRUE,main="classification tree")
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="waitin",ylab="Duaration")
predict(modFit,newdata=testing)
q()
pbeta(c(0.4,0.5,0.6),2,1)
qbeta(c(0.4,0.5,0.6),2,1)
dbeta(c(0.4,0.5,0.6),2,1)
install.packages("manipulate")
install.packages("manipulate")
library(manipulate)
myHist<-function(mu)
{ hist(galton$child,col="blue",breaks=100)}
myHist<-function(mu)
{ hist(galton$child,col="blue",breaks=100)
lines(c(mu,mu),c(0,150),col="red",lwd=5)
mse<-mean((galton$child-mu)^2)
text(63,150,paste("mu = ",mu))
text(63,140,paste("imbalance = ", round(mse,2)))
}
manipulate(myHist(mu),mu=slider(62,74,step=0.5))
(0.17-.12-.06)/2
(0.17-.012-.06)/2
(0.17-0.12-0.6)/2
(0.17-.012-.06)/2
x<-1:5
x<-1:4
p<-x/sum(x)
temp<-rbind(x,p)
rownames(temp)<-c("X","prob")
temp
mean(X)
mean(x)
temp[1,]
temp[2,]
sum(temp[1,]*temp[2,])
install.packages("shiny")
install.packages("shiny")
library(shiny)
q()
library(shiny)
runApp()
library(shiny)
library(shiny)
runApp()
devtools::install_github('rstudio/shinyapps')
library(shiny)
runGitHub("Programming Assignment2","anupama")
runGitHub("anupama","anupama")
runGitHub("datasharing","anupama")
runGitHub("datasciencecoursera","anupama")
q()
library(shiny)
setwd("C:/Users/Anupama/myown")
This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **Help** toolbar button for more details on using R Markdown).
library(knitr)
library(slidify)
library(shiny)
setwd("C:/Users/Anupama/myown/project")
library(randomForest)
library(foreach)
library(doParallel)
install.pacakages('doParallel')
install.pacakages('foreach')
require(doParallel)
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("doParallel")
install.packages("foreach")
library(foreach)
library(randomFoest)
library(Hmisc)
install.packages("randomForest")
install.packages("randomForest")
require(randomForest)
library(randomForest)
